---
title: "Homework 6 – Proof of recurrence formulas and implementation of "online" algorithms for mean and variance"
layout: post
date: 2025-11-03
mathjax: true
---


<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

# Statistics Homework

## Online (Incremental) Calculation of Mean and Variance

Instead of recalculating from all data each time, update in **O(1)** time using **constant memory**.

### Derivation

Given previous mean \\( \mu_{n-1} \\) and count \\( n-1 \\):

\\[
\mu_n = \mu_{n-1} + \frac{x_n - \mu_{n-1}}{n}
\\]

Let \\( \delta = x_n - \mu_{n-1} \\).  
Then update the running squared deviation:

\\[
M2\_n = M2\_{n-1} + \delta \,(x\_n - \mu\_n)
\\]


Population variance: \\( \sigma^2 = M2 / n \\)  
Sample variance: \\( s^2 = M2 / (n - 1) \\)

### JavaScript Implementation

```

// RunningStats: incremental mean and variance (Welford's method)
class RunningStats {
  constructor() {
    this.n = 0;
    this.mean = 0;
    this.M2 = 0;
  }

  push(x) {
    this.n += 1;
    const delta = x - this.mean;
    this.mean += delta / this.n;
    const delta2 = x - this.mean;
    this.M2 += delta * delta2;
  }

  getMean() {
    return this.n ? this.mean : NaN;
  }

  populationVariance() {
    return this.n ? this.M2 / this.n : NaN;
  }

  sampleVariance() {
    return this.n > 1 ? this.M2 / (this.n - 1) : NaN;
  }
}

// Example
const rs = new RunningStats();
[2, 4, 4, 4, 5, 5, 7, 9].forEach(x => rs.push(x));
console.log(rs.getMean());            // 5
console.log(rs.sampleVariance());     // 4
console.log(rs.populationVariance()); // 3.5
```
### Output
```
Mean: 5
Sample Variance: 4
Population Variance: 3.5
```
## Part 2: Efficiency: Online vs Classical Computation

| Aspect | Classical (Batch) | Online (Incremental) | More Efficient |
|--------|------------------|---------------------|----------------|
| Memory | Needs all *n* values | Constant memory (count, mean, M2) |  Online |
| Time per update | O(n) | O(1) |  Online |
| Numerical stability | Can suffer rounding errors | Stable (Welford’s method) |  Online |
| Parallel recompute | Easy to vectorize | Sequential by nature | Depends |
| Data access | Full dataset required | Streams data once |  Online |
| Implementation simplicity | Straightforward formula | Slightly more logic | Classical |

### Conclusion

Online computation of mean and variance is **more efficient** in most real-world scenarios:

- Uses **constant space**  
- Updates in **constant time**  
- Handles **streaming or large datasets**  
- Provides **better numerical stability**  

Online algorithms minimize rounding error and catastrophic cancellation by avoiding subtraction of large nearly equal sums, thus preventing overflow and cumulative floating-point error propagation.

Classical batch computation is only preferable for **small, static datasets** where all data are already in memory.
